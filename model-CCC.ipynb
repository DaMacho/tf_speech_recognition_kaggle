{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_classes': 12,\n",
    "    \n",
    "    # cnn 파라미터\n",
    "    'use_cnn': True,\n",
    "    'num_filters': [16, 32, 64, 64, 64, 64],\n",
    "    'filter_size': [7, 3, 3, 3, 3, 3],\n",
    "    'cnn_batch_norm' : [True, True, True, True, True, True],\n",
    "    'pool_sizes': [2, 2, 1, 1, 1, 2],\n",
    "    'cnn_dropout_keep_prob': [0, 0.2, 0.3, 0.25, 0.3, 0.3],\n",
    "    # dense 파라미터\n",
    "    'use_fc': False,\n",
    "    'fc_hidden_units': [1028, 512, 256],\n",
    "    'fc_batch_norm': [True, True, True],\n",
    "    'fc_dropout_keep_prob': [0.2, 0.3, 0.35],\n",
    "    \n",
    "    # rnn(lstm) 파라미터\n",
    "    'use_rnn': True,\n",
    "    'rnn_n_hiddens': [1028, 512],\n",
    "    'rnn_dropout_keep_prob': [0.6, 0.7],\n",
    "    \n",
    "    # Global Average Pooling / RNN이랑 동시사용불가\n",
    "    'use_GAP': False,\n",
    "    \n",
    "    'learning_rate': 0.001,\n",
    "    'activation': tf.nn.relu,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 5,\n",
    "    'height': 128,\n",
    "    'width': 100,\n",
    "    'model_path': './model/6conv_lstm_e5/' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Model:\n",
    "    def __init__(self, params,name):\n",
    "        # 하이퍼파라미터\n",
    "        self.num_classes = params['num_classes']\n",
    "        \n",
    "        self.use_cnn = params['use_cnn']\n",
    "        self.num_filters = params['num_filters']\n",
    "        self.filter_sizes = params['filter_size']\n",
    "        self.cnn_batch_norm  = params['cnn_batch_norm']\n",
    "        self.pool_sizes = params['pool_sizes']\n",
    "        self.cnn_dropout_keep_prob = params['cnn_dropout_keep_prob']\n",
    "        \n",
    "        \n",
    "        self.use_fc = params['use_fc']\n",
    "        self.fc_hidden_units = params['fc_hidden_units']\n",
    "        self.fc_batch_norm = params['fc_batch_norm']\n",
    "        self.fc_dropout_keep_prob = params['fc_dropout_keep_prob']\n",
    "        \n",
    "        self.use_rnn = params['use_rnn']\n",
    "        self.rnn_n_hiddens = params['rnn_n_hiddens']\n",
    "        self.rnn_dropout_keep_prob = params['rnn_dropout_keep_prob']\n",
    "        \n",
    "        self.use_GAP = params['use_GAP']\n",
    "        \n",
    "        self.learning_rate = params['learning_rate']\n",
    "        self.activation = params['activation']\n",
    "        \n",
    "        self.height = params['height']\n",
    "        self.width = params['width']\n",
    "        self.model_path = params['model_path']\n",
    "        self.idx_convolutional_layers = range(1, len(self.filter_sizes) + 1)\n",
    "        self.idx_fc_layers = range(1, len(self.fc_hidden_units) + 1)\n",
    "        self.idx_rnn_layers = range(1, len(self.rnn_n_hiddens) + 1)\n",
    "        self.name = name\n",
    "        \n",
    "\n",
    "    #  컨볼루션 레이어를 params에서 받은 파라미터를 따라 구축\n",
    "    def convolutional_layers(self, X, is_training = True, reuse = False):\n",
    "        \n",
    "        inputs = X\n",
    "        for i, num_filter, filter_size, use_bn, pool_size, keep_prob in zip(self.idx_convolutional_layers,\n",
    "                                                                            self.num_filters,\n",
    "                                                                            self.filter_sizes,\n",
    "                                                                            self.cnn_batch_norm,\n",
    "                                                                            self.pool_sizes,\n",
    "                                                                            self.cnn_dropout_keep_prob):            \n",
    "            L = tf.layers.conv2d(inputs,\n",
    "                                 filters=num_filter,\n",
    "                                 kernel_size=filter_size,\n",
    "                                 strides=1,\n",
    "                                 padding='SAME',\n",
    "                                 name = 'CONV'+str(i),\n",
    "                                 reuse= reuse)\n",
    "            if use_bn:\n",
    "                L= tf.layers.batch_normalization(L, training= is_training, name='BN' + str(i), reuse= reuse)\n",
    "            L = self.activation(L)\n",
    "            \n",
    "            if keep_prob:\n",
    "                L = tf.layers.dropout(L, keep_prob, training = is_training)\n",
    "            if pool_size != 1:\n",
    "                L = tf.layers.max_pooling2d(L, pool_size = pool_size, strides = pool_size, padding = 'SAME')\n",
    "            inputs = L\n",
    "        return inputs\n",
    "    \n",
    "    \n",
    "    #  dense 레이어를 params에서 받은 파라미터를 따라 구축\n",
    "    def fc_layers(self, X, is_training = True, reuse = False):\n",
    "        inputs = X\n",
    "        for i, units, use_bn, keep_prob in zip(self.idx_fc_layers, self.fc_hidden_units, self.fc_batch_norm, self.fc_dropout_keep_prob):\n",
    "            fc = tf.layers.dense(inputs,\n",
    "                                 units=units,\n",
    "                                 reuse=reuse,\n",
    "                                 name = 'FC' + str(i))\n",
    "            if use_bn:\n",
    "                fc = tf.layers.batch_normalization(fc, training= is_training, name='fc_BN' + str(i), reuse= reuse)\n",
    "            fc = self.activation(fc)\n",
    "            if keep_prob:\n",
    "                fc = tf.layers.dropout(fc, rate = keep_prob, training= is_training, name = 'fc_dropout' + str(i))\n",
    "            inputs = fc \n",
    "        return inputs\n",
    "  \n",
    "\n",
    "     # LSTM 레이어 \n",
    "    def rnn_layers(self, inputs, is_training = True, reuse = False):\n",
    "        if is_training:\n",
    "            keep_probs = self.rnn_dropout_keep_prob\n",
    "            \n",
    "        else:\n",
    "            keep_probs = np.ones_like(self.rnn_dropout_keep_prob)\n",
    "            \n",
    "        # single layer\n",
    "        if len(self.idx_rnn_layers) == 1:\n",
    "            cell = tf.nn.rnn_cell.BasicLSTMCell(self.rnn_n_hiddens[0], reuse = reuse)\n",
    "            cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_probs[0])\n",
    "        # multi layer \n",
    "        else:\n",
    "            cell_list = []\n",
    "            for i, n_hidden, keep_prob in zip(self.idx_rnn_layers, self.rnn_n_hiddens, keep_probs):\n",
    "                cell_ = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, reuse = reuse)\n",
    "                cell_ = tf.nn.rnn_cell.DropoutWrapper(cell_, output_keep_prob=keep_prob)\n",
    "                cell_list.append(cell_)\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(cell_list)\n",
    "        # output_shape [batch_size, width(n_step), n_classes]\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
    "        print(outputs.get_shape().as_list())\n",
    "        outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "        outputs = outputs[-1]\n",
    "        return outputs\n",
    " \n",
    "\n",
    "    def get_reshaped_cnn_to_rnn(self, inputs):\n",
    "        # [batch, height, width, n_feature map]\n",
    "        shape = inputs.get_shape().as_list() \n",
    "        # 우리가 얻어야하는 사이즈 [batch, width, height x n_feature map]\n",
    "        inputs = tf.transpose(inputs, [0, 2, 1, 3])\n",
    "        reshaped_inputs = tf.reshape(inputs, [-1, shape[2], shape[1] * shape[3]])\n",
    "        return reshaped_inputs\n",
    "  \n",
    "\n",
    "\n",
    "    # 모델 구축/ logit \n",
    "    def get_logits(self, X, is_training = True, reuse = False):\n",
    "        with tf.variable_scope(self.name):\n",
    "            L = X\n",
    "            if self.use_cnn:\n",
    "                L = self.convolutional_layers(L, is_training, reuse)\n",
    "\n",
    "            if self.use_GAP:\n",
    "                shape =L.get_shape().as_list()\n",
    "                # 글로벌 풀링 사이즈 (height, width)\n",
    "                if self.use_rnn:\n",
    "                    pool_size = (shape[1], 1)\n",
    "                pool_size = (shape[1], shape[2])\n",
    "                L= tf.layers.average_pooling2d(L, pool_size = pool_size, strides = 1, padding = 'VALID')\n",
    "                # 마지막 dense layer를 위한 flatten\n",
    "                L = tf.layers.flatten(L)\n",
    "\n",
    "            if self.use_rnn:\n",
    "                reshaped_fp = self.get_reshaped_cnn_to_rnn(L)\n",
    "                L = self.rnn_layers(reshaped_fp, is_training, reuse)\n",
    "                                \n",
    "            if self.use_fc:\n",
    "                if not self.use_GAP:\n",
    "                    L = tf.layers.flatten(L)\n",
    "                L = self.fc_layers(L, is_training, reuse)\n",
    "            \n",
    "                       \n",
    "            output = tf.layers.dense(L, units= self.num_classes, reuse=reuse, name = 'out')\n",
    "            return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_parser(serialized_example):\n",
    "    features = {\n",
    "        \"spectrum\": tf.FixedLenFeature([128 * 100], tf.float32),\n",
    "        \"label\": tf.FixedLenFeature([12], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "\n",
    "    spec = parsed_feature['spectrum']\n",
    "    label = parsed_feature['label']\n",
    "\n",
    "    return spec, label\n",
    "        \n",
    "    \n",
    "def test_parser(serialized_example):\n",
    "    features = {\n",
    "        \"spectrum\": tf.FixedLenFeature([128 * 100], tf.float32),\n",
    "    }\n",
    "\n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "\n",
    "    spec = parsed_feature['spectrum']\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 13, 512]\n",
      "[None, 13, 512]\n",
      "[None, 13, 512]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "test_data_dir = \"../data/tfrecords/test_final.tfrecord\"\n",
    "train_data_dir = \"../data/tfrecords/train_final.tfrecord\"\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(train_data_dir).map(train_parser)\n",
    "train_dataset = train_dataset.shuffle(700000, seed = 1)\n",
    "train_dataset = train_dataset.batch(params['batch_size'])\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset(test_data_dir).map(test_parser)\n",
    "test_dataset = test_dataset.batch(params['batch_size'])\n",
    "\n",
    "train_itr = tf.contrib.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "test_itr = tf.contrib.data.Iterator.from_structure(test_dataset.output_types, test_dataset.output_shapes)\n",
    "\n",
    "spec, label = train_itr.get_next()\n",
    "test_spec = test_itr.get_next()\n",
    "\n",
    "spec = tf.reshape(spec, [-1, 128, 100, 1])\n",
    "spec = tf.cast(spec, tf.float32)\n",
    "\n",
    "test_spec = tf.reshape(test_spec, [-1, 128, 100, 1])\n",
    "test_spec = tf.cast(test_spec, tf.float32)\n",
    "\n",
    "train_init_op = train_itr.make_initializer(train_dataset)\n",
    "test_init_op = test_itr.make_initializer(test_dataset)\n",
    "\n",
    "name = 'model'\n",
    "model = Model(params, 'model')\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    X = tf.placeholder(tf.float32, [None, params['height'], params['width'], 1])\n",
    "    Y = tf.placeholder(tf.float32, [None, params['num_classes']])\n",
    "    global_step = tf.Variable(0, trainable = False, name = 'global_step')\n",
    "\n",
    "    logits_train = model.get_logits(X)                              \n",
    "    loss = tf.losses.softmax_cross_entropy(Y, logits_train)   \n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=name)            \n",
    "    with tf.control_dependencies(update_ops):    \n",
    "        optimizer = tf.train.AdamOptimizer(params['learning_rate']).minimize(loss, global_step=global_step)\n",
    "        \n",
    "    #eval\n",
    "    logits_eval = model.get_logits(X, is_training=False, reuse=True)\n",
    "    predict_proba_ = tf.nn.softmax(logits_eval)\n",
    "    prediction = tf.argmax(predict_proba_, 1)\n",
    "    accuracy = tf.metrics.accuracy(tf.argmax(Y, 1), prediction)\n",
    "    \n",
    "    #predict\n",
    "    logits_test = model.get_logits(X, is_training=False, reuse=True)\n",
    "    test_predict_proba_ = tf.nn.softmax(logits_test)\n",
    "    test_prediction = tf.argmax(test_predict_proba_, 1)\n",
    "    \n",
    "    # 변수 프린트/ 텐서보드 summary 생성            \n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "    \n",
    "#     for v in tf.trainable_variables():\n",
    "#         tf.summary.histogram('Var_{}'.format(v.name), v)\n",
    "#         print(v)\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, cost: 2.7028439044952393\n",
      "step: 500, cost: 0.4938085675239563\n",
      "step: 1000, cost: 0.38135242462158203\n",
      "step: 1500, cost: 0.21590806543827057\n",
      "step: 2000, cost: 0.15291017293930054\n",
      "epoch: 0, cost : 0.1843324452638626, train_acc: 0.7470812201499939, acc; 0.8612012267112732\n",
      "step: 2500, cost: 0.23617693781852722\n",
      "step: 3000, cost: 0.12155231833457947\n",
      "step: 3500, cost: 0.06286904960870743\n",
      "step: 4000, cost: 0.06124712899327278\n",
      "epoch: 1, cost : 0.19882212579250336, train_acc: 0.8917738795280457, acc; 0.9108495116233826\n",
      "step: 4500, cost: 0.06294667720794678\n",
      "step: 5000, cost: 0.24623721837997437\n",
      "step: 5500, cost: 0.0916653648018837\n",
      "step: 6000, cost: 0.0851302444934845\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "# model restore (writer 이하는 주석처리)\n",
    "#new_saver = tf.train.import_meta_graph('./model/6conv_lstm_e5/6conv_lstm_e5.ckpt-21070.meta')\n",
    "#new_saver.restore(sess, tf.train.latest_checkpoint('./model/6conv_lstm_e5/'))\n",
    "\n",
    "writer = tf.summary.FileWriter('./logs_new/6conv_lstm_e5_2/', sess.graph)\n",
    "        \n",
    "for epoch in range(params['epochs']):\n",
    "    sess.run(train_init_op)\n",
    "    acc = []\n",
    "    train_acc = []\n",
    "    for i in range(2186):\n",
    "        try:\n",
    "            step = sess.run(global_step)\n",
    "            \n",
    "            _spec, _label = sess.run([spec, label])\n",
    "            _, c, _summ = sess.run([optimizer, loss, merged], feed_dict = {X: _spec, Y: _label})\n",
    "            acc_train = sess.run(accuracy, feed_dict = {X: _spec, Y: _label})\n",
    "            \n",
    "            train_acc.append(acc_train[1])\n",
    "            \n",
    "            writer.add_summary(_summ, step)\n",
    "            \n",
    "            if step % 500 == 0:\n",
    "                print('step: {}, cost: {}'.format(step, c))\n",
    "                \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break \n",
    "    while True:\n",
    "        try:\n",
    "            _spec, _label = sess.run([spec, label])\n",
    "            val_acc = sess.run(accuracy, feed_dict = {X: _spec, Y: _label})\n",
    "            \n",
    "            acc.append(val_acc[1]) \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    print('epoch: {}, cost : {}, train_acc: {}, acc; {}'.format(epoch, c, np.mean(train_acc), np.mean(acc)))\n",
    "\n",
    "saver.save(sess, './model/6conv_lstm_e5_2/6conv_lstm_e5.ckpt', global_step=sess.run(global_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- total batch : 3122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2185.3999999999996"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3122*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/6conv_2lstm_/6conv_2lstm_.ckpt-21070'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, './model/6conv_2lstm_/6conv_2lstm_.ckpt', global_step=sess.run(global_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5443  5430  5234  5810  6157  6546  5254  7299  5494 94569  5952  5350]\n",
      "158538\n"
     ]
    }
   ],
   "source": [
    "sess.run(test_init_op)\n",
    "\n",
    "test_spec_ = sess.run(test_spec)\n",
    "predict = sess.run(test_prediction, feed_dict={X: test_spec_})\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        test_spec_ = sess.run(test_spec)\n",
    "        predict = np.hstack([predict, sess.run(test_prediction, feed_dict={X: test_spec_})])\n",
    "        \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "        \n",
    "print(np.bincount(predict))\n",
    "print(len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158538, 12)\n"
     ]
    }
   ],
   "source": [
    "sess.run(test_init_op)\n",
    "\n",
    "test_spec_ = sess.run(test_spec)\n",
    "predict_proba = sess.run(test_predict_proba_, feed_dict={X: test_spec_})\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        test_spec_ = sess.run(test_spec)\n",
    "        predict_proba = np.vstack([predict_proba, sess.run(test_predict_proba_, feed_dict={X: test_spec_})])\n",
    "        \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "        \n",
    "predict_proba = np.array(predict_proba)\n",
    "print(predict_proba.shape)\n",
    "\n",
    "pp = pd.DataFrame(predict_proba, index = files)\n",
    "pp.to_csv('6conv_2lstm_predict_proba.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yes : [0 0 0 0 0 0 0 0 0 0 0 1]\n",
    "# no : [0 0 0 1 0 0 0 0 0 0 0 0]\n",
    "# up : [0 0 0 0 0 0 0 0 0 0 1 0]\n",
    "# down : [1 0 0 0 0 0 0 0 0 0 0 0]\n",
    "# left : [0 0 1 0 0 0 0 0 0 0 0 0]\n",
    "# right : [0 0 0 0 0 0 1 0 0 0 0 0]\n",
    "# on : [0 0 0 0 0 1 0 0 0 0 0 0]\n",
    "# off : [0 0 0 0 1 0 0 0 0 0 0 0]\n",
    "# stop : [0 0 0 0 0 0 0 0 1 0 0 0]\n",
    "# go : [0 1 0 0 0 0 0 0 0 0 0 0]\n",
    "# unknown : [0 0 0 0 0 0 0 0 0 1 0 0]\n",
    "# silence : [0 0 0 0 0 0 0 1 0 0 0 0]\n",
    "\n",
    "class_names = ['down', 'go', 'left', 'no', 'off', 'on', 'right', 'silence', 'stop', 'unknown', 'up', 'yes']\n",
    "\n",
    "audio_path = '../data/test/audio/'\n",
    "\n",
    "files = os.listdir(audio_path)\n",
    "files = sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158538"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = pd.DataFrame(predict_proba, index = files)\n",
    "pp.to_csv('6conv_2lstm_predict_proba.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.to_csv('6conv_2lstm_predict_proba.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(files[1500], '/', predict[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(audio_path + 'clip_0000adecb.wav', rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission.csv 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./sub/6conv_2lstm_.csv', 'w') as f:\n",
    "    fieldnames=['fname', 'label']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for i in range(len(predict)):\n",
    "        writer.writerow({'fname': files[i], 'label': class_names[predict[i]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./sub/6conv_2lstm_.csv_predict_proba', 'w') as f:\n",
    "    fieldnames=['fname', 'label']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for i in range(len(predict)):\n",
    "        writer.writerow({'fname': files[i], 'label': class_names[predict[i]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('./6conv_2lstm_.csv')\n",
    "# for i in range(len(temp[\"label\"])):\n",
    "#     if temp['label'][i] == 'silence':\n",
    "#         temp['label'][i] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(temp, \"./6conv_2lstm_temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clip_000044442.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clip_0000adecb.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clip_0000d4322.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip_0000fb6fe.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clip_0001d1559.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clip_0002256ed.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clip_0002a4a1f.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clip_0002d9b83.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clip_000373a5b.wav</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clip_0003c7122.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clip_0003e6aee.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clip_00049951d.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clip_0004c6707.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>clip_0004f8b63.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clip_00068e281.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>clip_00069e9cb.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>clip_0006f7b8b.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>clip_0007ec7e6.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>clip_00082a7d6.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>clip_00094eb22.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clip_000962cbb.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>clip_000a96d0a.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>clip_000b01093.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>clip_000b378f1.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>clip_000b9514b.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>clip_000c07b07.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>clip_000c2c07b.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>clip_000c41da7.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>clip_000dcdd2c.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>clip_000ed5715.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158508</th>\n",
       "      <td>clip_fff52eef1.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158509</th>\n",
       "      <td>clip_fff598c64.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158510</th>\n",
       "      <td>clip_fff5b4952.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158511</th>\n",
       "      <td>clip_fff658fdd.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158512</th>\n",
       "      <td>clip_fff662589.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158513</th>\n",
       "      <td>clip_fff686d73.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158514</th>\n",
       "      <td>clip_fff6bc673.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158515</th>\n",
       "      <td>clip_fff70a77a.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158516</th>\n",
       "      <td>clip_fff7ee6d3.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158517</th>\n",
       "      <td>clip_fff84d65e.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158518</th>\n",
       "      <td>clip_fff88c060.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158519</th>\n",
       "      <td>clip_fff8cf4b7.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158520</th>\n",
       "      <td>clip_fff8d8cb6.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158521</th>\n",
       "      <td>clip_fff8e76f9.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158522</th>\n",
       "      <td>clip_fff95115c.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158523</th>\n",
       "      <td>clip_fff97297a.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158524</th>\n",
       "      <td>clip_fff993190.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158525</th>\n",
       "      <td>clip_fff9c6301.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158526</th>\n",
       "      <td>clip_fffa7b86f.wav</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158527</th>\n",
       "      <td>clip_fffb4672e.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158528</th>\n",
       "      <td>clip_fffb489d7.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158529</th>\n",
       "      <td>clip_fffc6f612.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158530</th>\n",
       "      <td>clip_fffcf6cac.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158531</th>\n",
       "      <td>clip_fffd28721.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158532</th>\n",
       "      <td>clip_fffd5cf54.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158533</th>\n",
       "      <td>clip_fffe49419.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158534</th>\n",
       "      <td>clip_ffff2fb36.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158535</th>\n",
       "      <td>clip_ffff90f56.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158536</th>\n",
       "      <td>clip_ffff98589.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158537</th>\n",
       "      <td>clip_ffffc7358.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fname    label\n",
       "0       clip_000044442.wav       no\n",
       "1       clip_0000adecb.wav  unknown\n",
       "2       clip_0000d4322.wav  unknown\n",
       "3       clip_0000fb6fe.wav  unknown\n",
       "4       clip_0001d1559.wav  unknown\n",
       "5       clip_0002256ed.wav  unknown\n",
       "6       clip_0002a4a1f.wav  unknown\n",
       "7       clip_0002d9b83.wav  unknown\n",
       "8       clip_000373a5b.wav       go\n",
       "9       clip_0003c7122.wav  unknown\n",
       "10      clip_0003e6aee.wav      off\n",
       "11      clip_00049951d.wav  unknown\n",
       "12      clip_0004c6707.wav  unknown\n",
       "13      clip_0004f8b63.wav      yes\n",
       "14      clip_00068e281.wav       no\n",
       "15      clip_00069e9cb.wav     stop\n",
       "16      clip_0006f7b8b.wav  unknown\n",
       "17      clip_0007ec7e6.wav     down\n",
       "18      clip_00082a7d6.wav  unknown\n",
       "19      clip_00094eb22.wav  unknown\n",
       "20      clip_000962cbb.wav  unknown\n",
       "21      clip_000a96d0a.wav  unknown\n",
       "22      clip_000b01093.wav  unknown\n",
       "23      clip_000b378f1.wav  unknown\n",
       "24      clip_000b9514b.wav  unknown\n",
       "25      clip_000c07b07.wav  unknown\n",
       "26      clip_000c2c07b.wav  unknown\n",
       "27      clip_000c41da7.wav       on\n",
       "28      clip_000dcdd2c.wav  unknown\n",
       "29      clip_000ed5715.wav     down\n",
       "...                    ...      ...\n",
       "158508  clip_fff52eef1.wav  unknown\n",
       "158509  clip_fff598c64.wav       up\n",
       "158510  clip_fff5b4952.wav       on\n",
       "158511  clip_fff658fdd.wav  unknown\n",
       "158512  clip_fff662589.wav     left\n",
       "158513  clip_fff686d73.wav       no\n",
       "158514  clip_fff6bc673.wav    right\n",
       "158515  clip_fff70a77a.wav    right\n",
       "158516  clip_fff7ee6d3.wav  unknown\n",
       "158517  clip_fff84d65e.wav  unknown\n",
       "158518  clip_fff88c060.wav       no\n",
       "158519  clip_fff8cf4b7.wav  unknown\n",
       "158520  clip_fff8d8cb6.wav  unknown\n",
       "158521  clip_fff8e76f9.wav  unknown\n",
       "158522  clip_fff95115c.wav  unknown\n",
       "158523  clip_fff97297a.wav  unknown\n",
       "158524  clip_fff993190.wav      yes\n",
       "158525  clip_fff9c6301.wav  unknown\n",
       "158526  clip_fffa7b86f.wav       on\n",
       "158527  clip_fffb4672e.wav  unknown\n",
       "158528  clip_fffb489d7.wav       no\n",
       "158529  clip_fffc6f612.wav  unknown\n",
       "158530  clip_fffcf6cac.wav  unknown\n",
       "158531  clip_fffd28721.wav    right\n",
       "158532  clip_fffd5cf54.wav  unknown\n",
       "158533  clip_fffe49419.wav  unknown\n",
       "158534  clip_ffff2fb36.wav     down\n",
       "158535  clip_ffff90f56.wav     stop\n",
       "158536  clip_ffff98589.wav  unknown\n",
       "158537  clip_ffffc7358.wav  unknown\n",
       "\n",
       "[158538 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = pd.read_csv('./6conv_2lstm_temp.csv')\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    101868\n",
       "on           6546\n",
       "off          6157\n",
       "up           5952\n",
       "no           5810\n",
       "stop         5494\n",
       "down         5443\n",
       "go           5430\n",
       "yes          5350\n",
       "right        5254\n",
       "left         5234\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    94569\n",
       "silence     7299\n",
       "on          6546\n",
       "off         6157\n",
       "up          5952\n",
       "no          5810\n",
       "stop        5494\n",
       "down        5443\n",
       "go          5430\n",
       "yes         5350\n",
       "right       5254\n",
       "left        5234\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 11 04:18:46 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    34W / 300W |  13508MiB / 16152MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     15524      C   ...naconda3/envs/tensorflow_p36/bin/python 13498MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
